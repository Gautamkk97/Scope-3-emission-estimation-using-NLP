{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9425dde-25b3-45a2-9af1-8b0a18a89784",
   "metadata": {},
   "source": [
    "Zero shot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0715e9d-318e-4be1-941d-477d7d8c86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('useeio.csv')\n",
    "\n",
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "# Define a function to perform zero-shot classification and evaluate metrics\n",
    "def zero_shot_classification_and_evaluation(texts, true_labels, candidate_labels):\n",
    "    predictions = [classifier(text, candidate_labels)['labels'][0] for text in texts]\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Define the classification tasks\n",
    "tasks = {\n",
    "    \"Commodity or Industry Classification\": {\n",
    "        \"texts\": data['commodity_industry_description'].tolist(),\n",
    "        \"true_labels\": data['commodity_industry_label'].tolist(),\n",
    "        \"candidate_labels\": [\"commodity\", \"industry\"]\n",
    "    },\n",
    "    \"Emission Type Identification\": {\n",
    "        \"texts\": data['emission_description'].tolist(),\n",
    "        \"true_labels\": data['emission_type_label'].tolist(),\n",
    "        \"candidate_labels\": [\"CO2\", \"CH4\", \"N2O\"]\n",
    "    },\n",
    "    \"Impact Assessment\": {\n",
    "        \"texts\": data['impact_description'].tolist(),\n",
    "        \"true_labels\": data['impact_label'].tolist(),\n",
    "        \"candidate_labels\": [\"low impact\", \"medium impact\", \"high impact\"]\n",
    "    },\n",
    "    \"Supply Chain Stage Identification\": {\n",
    "        \"texts\": data['supply_chain_stage_description'].tolist(),\n",
    "        \"true_labels\": data['supply_chain_stage_label'].tolist(),\n",
    "        \"candidate_labels\": [\"production\", \"transportation\", \"distribution\"]\n",
    "    },\n",
    "    \"Geographical Region Identification\": {\n",
    "        \"texts\": data['geographical_region_description'].tolist(),\n",
    "        \"true_labels\": data['geographical_region_label'].tolist(),\n",
    "        \"candidate_labels\": [\"North America\", \"Europe\", \"Asia\"]\n",
    "    },\n",
    "    \"Temporal Trend Prediction\": {\n",
    "        \"texts\": data['temporal_trend_description'].tolist(),\n",
    "        \"true_labels\": data['temporal_trend_label'].tolist(),\n",
    "        \"candidate_labels\": [\"increase\", \"decrease\", \"stable\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform zero-shot classification and collect results\n",
    "results = {}\n",
    "for task_name, task_data in tasks.items():\n",
    "    accuracy, precision, recall, f1 = zero_shot_classification_and_evaluation(\n",
    "        task_data['texts'], task_data['true_labels'], task_data['candidate_labels'])\n",
    "    results[task_name] = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Display the results in a table\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Plot the results in a graph\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "for metric in metrics:\n",
    "    plt.plot(results_df.index, results_df[metric], marker='o', label=metric)\n",
    "\n",
    "plt.xlabel(\"Tasks\")\n",
    "plt.ylabel(\"Scores\")\n",
    "plt.title(\"Comparison of Zero-Shot Classification Tasks\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94410a87-9d37-42ab-978d-e21d1cd37b32",
   "metadata": {},
   "source": [
    "Results for supervised learning using classical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca076f0-c889-42c5-8ecc-a2b8f71cb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('useeio.csv')\n",
    "\n",
    "# Preprocess the data (example, adjust according to your dataset)\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for column in ['commodity_industry_label', 'emission_type_label', 'impact_label', 'supply_chain_stage_label', 'geographical_region_label', 'temporal_trend_label']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the data into features and target variables for each task\n",
    "features = data['text_description']  # Assuming all tasks use the same text features, adjust as necessary\n",
    "\n",
    "# Create SBERT embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_embeddings = sbert_model.encode(features.tolist())\n",
    "\n",
    "# Emission Quantity Prediction\n",
    "emission_quantity = data['emission_quantity'].values  # Replace with actual column\n",
    "\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(sbert_embeddings, emission_quantity)\n",
    "lin_reg_predictions = lin_reg.predict(sbert_embeddings)\n",
    "lin_reg_accuracy = lin_reg.score(sbert_embeddings, emission_quantity)\n",
    "lin_reg_mse = mean_squared_error(emission_quantity, lin_reg_predictions)\n",
    "\n",
    "# Random Forest Regression\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(sbert_embeddings, emission_quantity)\n",
    "rf_reg_predictions = rf_reg.predict(sbert_embeddings)\n",
    "rf_reg_accuracy = rf_reg.score(sbert_embeddings, emission_quantity)\n",
    "rf_reg_mse = mean_squared_error(emission_quantity, rf_reg_predictions)\n",
    "\n",
    "# Gradient Boosting Regression\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "gb_reg.fit(sbert_embeddings, emission_quantity)\n",
    "gb_reg_predictions = gb_reg.predict(sbert_embeddings)\n",
    "gb_reg_accuracy = gb_reg.score(sbert_embeddings, emission_quantity)\n",
    "gb_reg_mse = mean_squared_error(emission_quantity, gb_reg_predictions)\n",
    "\n",
    "# Print results for Emission Quantity Prediction\n",
    "print(\"Emission Quantity Prediction:\")\n",
    "print(f\"Linear Regression - Accuracy: {lin_reg_accuracy:.2f}, MSE: {lin_reg_mse:.4f}\")\n",
    "print(f\"Random Forest Regression - Accuracy: {rf_reg_accuracy:.2f}, MSE: {rf_reg_mse:.4f}\")\n",
    "print(f\"Gradient Boosting Regression - Accuracy: {gb_reg_accuracy:.2f}, MSE: {gb_reg_mse:.4f}\")\n",
    "\n",
    "# Emission Type Identification\n",
    "emission_type = data['emission_type_label'].values\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(sbert_embeddings, emission_type)\n",
    "log_reg_predictions = log_reg.predict(sbert_embeddings)\n",
    "log_reg_accuracy = accuracy_score(emission_type, log_reg_predictions)\n",
    "log_reg_precision = precision_score(emission_type, log_reg_predictions, average='weighted')\n",
    "log_reg_recall = recall_score(emission_type, log_reg_predictions, average='weighted')\n",
    "log_reg_f1 = f1_score(emission_type, log_reg_predictions, average='weighted')\n",
    "\n",
    "# Support Vector Machines\n",
    "svm = SVC()\n",
    "svm.fit(sbert_embeddings, emission_type)\n",
    "svm_predictions = svm.predict(sbert_embeddings)\n",
    "svm_accuracy = accuracy_score(emission_type, svm_predictions)\n",
    "svm_precision = precision_score(emission_type, svm_predictions, average='weighted')\n",
    "svm_recall = recall_score(emission_type, svm_predictions, average='weighted')\n",
    "svm_f1 = f1_score(emission_type, svm_predictions, average='weighted')\n",
    "\n",
    "# Decision Trees\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(sbert_embeddings, emission_type)\n",
    "tree_predictions = tree.predict(sbert_embeddings)\n",
    "tree_accuracy = accuracy_score(emission_type, tree_predictions)\n",
    "tree_f1 = f1_score(emission_type, tree_predictions, average='weighted')\n",
    "\n",
    "# Print results for Emission Type Identification\n",
    "print(\"\\nEmission Type Identification:\")\n",
    "print(f\"Logistic Regression - Accuracy: {log_reg_accuracy:.2f}, Precision: {log_reg_precision:.2f}, Recall: {log_reg_recall:.2f}, F1: {log_reg_f1:.2f}\")\n",
    "print(f\"Support Vector Machines - Accuracy: {svm_accuracy:.2f}, Precision: {svm_precision:.2f}, Recall: {svm_recall:.2f}, F1: {svm_f1:.2f}\")\n",
    "print(f\"Decision Trees - Accuracy: {tree_accuracy:.2f}, F1: {tree_f1:.2f}\")\n",
    "\n",
    "# Impact Assessment\n",
    "impact = data['impact_label'].values\n",
    "\n",
    "# Binary Relevance\n",
    "binary_relevance = MultiOutputClassifier(LogisticRegression())\n",
    "binary_relevance.fit(sbert_embeddings, impact)\n",
    "binary_relevance_predictions = binary_relevance.predict(sbert_embeddings)\n",
    "binary_relevance_accuracy = accuracy_score(impact, binary_relevance_predictions)\n",
    "binary_relevance_precision = precision_score(impact, binary_relevance_predictions, average='weighted')\n",
    "binary_relevance_recall = recall_score(impact, binary_relevance_predictions, average='weighted')\n",
    "binary_relevance_f1 = f1_score(impact, binary_relevance_predictions, average='weighted')\n",
    "\n",
    "# Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "label_powerset = LabelPowerset(LogisticRegression())\n",
    "label_powerset.fit(sbert_embeddings, impact)\n",
    "label_powerset_predictions = label_powerset.predict(sbert_embeddings)\n",
    "label_powerset_accuracy = accuracy_score(impact, label_powerset_predictions)\n",
    "label_powerset_f1 = f1_score(impact, label_powerset_predictions, average='weighted')\n",
    "\n",
    "# Print results for Impact Assessment\n",
    "print(\"\\nImpact Assessment:\")\n",
    "print(f\"Binary Relevance - Accuracy: {binary_relevance_accuracy:.2f}, Precision: {binary_relevance_precision:.2f}, Recall: {binary_relevance_recall:.2f}, F1: {binary_relevance_f1:.2f}\")\n",
    "print(f\"Label Powerset - Accuracy: {label_powerset_accuracy:.2f}, F1: {label_powerset_f1:.2f}\")\n",
    "\n",
    "# Supply Chain Stage Identification\n",
    "supply_chain_stage = data['supply_chain_stage_label'].values\n",
    "\n",
    "# Conditional Random Fields\n",
    "from sklearn_crfsuite import CRF\n",
    "crf = CRF()\n",
    "crf.fit(sbert_embeddings, supply_chain_stage)\n",
    "crf_predictions = crf.predict(sbert_embeddings)\n",
    "crf_accuracy = accuracy_score(supply_chain_stage, crf_predictions)\n",
    "crf_f1 = f1_score(supply_chain_stage, crf_predictions, average='weighted')\n",
    "\n",
    "# Hidden Markov Models\n",
    "from hmmlearn import hmm\n",
    "hmm_model = hmm.GaussianHMM()\n",
    "hmm_model.fit(sbert_embeddings, supply_chain_stage)\n",
    "hmm_predictions = hmm_model.predict(sbert_embeddings)\n",
    "hmm_accuracy = accuracy_score(supply_chain_stage, hmm_predictions)\n",
    "hmm_f1 = f1_score(supply_chain_stage, hmm_predictions, average='weighted')\n",
    "\n",
    "# Print results for Supply Chain Stage Identification\n",
    "print(\"\\nSupply Chain Stage Identification:\")\n",
    "print(f\"Conditional Random Fields - Accuracy: {crf_accuracy:.2f}, F1: {crf_f1:.2f}\")\n",
    "print(f\"Hidden Markov Models - Accuracy: {hmm_accuracy:.2f}, F1: {hmm_f1:.2f}\")\n",
    "\n",
    "# Geographical Region Classification\n",
    "geographical_region = data['geographical_region_label'].values\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(sbert_embeddings, geographical_region)\n",
    "knn_predictions = knn.predict(sbert_embeddings)\n",
    "knn_accuracy = accuracy_score(geographical_region, knn_predictions)\n",
    "knn_precision = precision_score(geographical_region, knn_predictions, average='weighted')\n",
    "knn_recall = recall_score(geographical_region, knn_predictions, average='weighted')\n",
    "knn_f1 = f1_score(geographical_region, knn_predictions, average='weighted')\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(sbert_embeddings, geographical_region)\n",
    "nb_predictions = nb.predict(sbert_embeddings)\n",
    "nb_accuracy = accuracy_score(geographical_region, nb_predictions)\n",
    "nb_precision = precision_score(geographical_region, nb_predictions, average='weighted')\n",
    "nb_recall = recall_score(geographical_region, nb_predictions, average='weighted')\n",
    "nb_f1 = f1_score(geographical_region, nb_predictions, average='weighted')\n",
    "\n",
    "# Print results for Geographical Region Classification\n",
    "print(\"\\nGeographical Region Classification:\")\n",
    "print(f\"k-Nearest Neighbors - Accuracy: {knn_accuracy:.2f}, Precision: {knn_precision:.2f}, Recall: {knn_recall:.2f}, F1: {knn_f1:.2f}\")\n",
    "print(f\"Naive Bayes - Accuracy: {nb_accuracy:.2f}, Precision: {nb_precision:.2f}, Recall: {nb_recall:.2f}, F1: {nb_f1:.2f}\")\n",
    "\n",
    "# Temporal Trend Prediction\n",
    "temporal_trend = data['temporal_trend'].values\n",
    "\n",
    "# ARIMA\n",
    "arima_model = ARIMA(temporal_trend, order=(5, 1, 0))\n",
    "arima_fit = arima_model.fit()\n",
    "arima_predictions = arima_fit.predict()\n",
    "arima_mse = mean_squared_error(temporal_trend, arima_predictions)\n",
    "\n",
    "# Exponential Smoothing\n",
    "exp_smoothing = ExponentialSmoothing(temporal_trend)\n",
    "exp_smoothing_fit = exp_smoothing.fit()\n",
    "exp_smoothing_predictions = exp_smoothing_fit.predict()\n",
    "exp_smoothing_mse = mean_squared_error(temporal_trend, exp_smoothing_predictions)\n",
    "\n",
    "# Print results for Temporal Trend Prediction\n",
    "print(\"\\nTemporal Trend Prediction:\")\n",
    "print(f\"ARIMA - MSE: {arima_mse:.4f}\")\n",
    "print(f\"Exponential Smoothing - MSE: {exp_smoothing_mse:.4f}\")\n",
    "\n",
    "# TF-IDF and Word2Vec Embeddings\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(features).toarray()\n",
    "\n",
    "# Word2Vec\n",
    "word2vec_model = Word2Vec(features.apply(lambda x: x.split()), vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_features = np.array([np.mean([word2vec_model.wv[word] for word in text.split() if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for text in features])\n",
    "\n",
    "# SVM Classifier\n",
    "svm_tfidf = SVC()\n",
    "svm_tfidf.fit(tfidf_features, emission_type)\n",
    "svm_tfidf_predictions = svm_tfidf.predict(tfidf_features)\n",
    "svm_tfidf_accuracy = accuracy_score(emission_type, svm_tfidf_predictions)\n",
    "\n",
    "svm_word2vec = SVC()\n",
    "svm_word2vec.fit(word2vec_features, emission_type)\n",
    "svm_word2vec_predictions = svm_word2vec.predict(word2vec_features)\n",
    "svm_word2vec_accuracy = accuracy_score(emission_type, svm_word2vec_predictions)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_tfidf = RandomForestClassifier()\n",
    "rf_tfidf.fit(tfidf_features, emission_type)\n",
    "rf_tfidf_predictions = rf_tfidf.predict(tfidf_features)\n",
    "rf_tfidf_accuracy = accuracy_score(emission_type, rf_tfidf_predictions)\n",
    "\n",
    "rf_word2vec = RandomForestClassifier()\n",
    "rf_word2vec.fit(word2vec_features, emission_type)\n",
    "rf_word2vec_predictions = rf_word2vec.predict(word2vec_features)\n",
    "rf_word2vec_accuracy = accuracy_score(emission_type, rf_word2vec_predictions)\n",
    "\n",
    "# Print results for TF-IDF and Word2Vec\n",
    "print(\"\\nTF-IDF and Word2Vec Embeddings:\")\n",
    "print(f\"SVM (TF-IDF) - Accuracy: {svm_tfidf_accuracy:.2f}\")\n",
    "print(f\"SVM (Word2Vec) - Accuracy: {svm_word2vec_accuracy:.2f}\")\n",
    "print(f\"Random Forest (TF-IDF) - Accuracy: {rf_tfidf_accuracy:.2f}\")\n",
    "print(f\"Random Forest (Word2Vec) - Accuracy: {rf_word2vec_accuracy:.2f}\")\n",
    "\n",
    "# Plotting results (example for Emission Type Identification)\n",
    "tasks = ['Emission Quantity Prediction', 'Emission Type Identification', 'Impact Assessment', 'Supply Chain Stage Identification', 'Geographical Region Classification', 'Temporal Trend Prediction']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "results = {\n",
    "    'Emission Type Identification': [log_reg_accuracy, log_reg_precision, log_reg_recall, log_reg_f1],\n",
    "    'Supply Chain Stage Identification': [crf_accuracy, None, None, crf_f1],\n",
    "    'Geographical Region Classification': [knn_accuracy, knn_precision, knn_recall, knn_f1]\n",
    "    # Add other results similarly\n",
    "}\n",
    "\n",
    "for metric in metrics:\n",
    "    for task, values in results.items():\n",
    "        plt.plot(tasks, values, marker='o', label=task)\n",
    "\n",
    "plt.xlabel('Tasks')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Comparison of Classification Tasks')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eded89e-41a7-4f25-bebe-d4b61bd9ce08",
   "metadata": {},
   "source": [
    "Results of fine-tuning BERT for SCOPE 3 emission estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acfdf8-4a33-404a-a5c9-01de6986b15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
