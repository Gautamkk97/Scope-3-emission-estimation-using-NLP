{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11a3bfc-ea89-4ad0-8862-a2f9853381c8",
   "metadata": {},
   "source": [
    "Detailed Results and Inferences on SBERT Architectures Using the USEEIO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5956f-07e2-42cf-a895-912a49a4eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Load your dataset (assuming the dataset is in CSV format)\n",
    "data = pd.read_csv('useeio_dataset.csv')\n",
    "\n",
    "# Preprocess the data (example, adjust according to your dataset)\n",
    "# Assume 'text' is the column with textual descriptions and 'label' is the target variable.\n",
    "features = data['text_description'].tolist()\n",
    "labels = data['emission_label'].values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28145de0-9cfe-45cf-a238-a6726efbcbc5",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4767b-4f8c-487e-ad59-daa22d7caf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, train_texts, train_labels, test_texts, test_labels):\n",
    "    # Load the SBERT model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Encode the texts\n",
    "    train_embeddings = model.encode(train_texts, convert_to_tensor=True)\n",
    "    test_embeddings = model.encode(test_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "\n",
    "    # Use a simple classifier (e.g., logistic regression)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(train_embeddings.cpu().numpy(), train_labels.cpu().numpy())\n",
    "\n",
    "    # Predict on test set\n",
    "    start_time = time.time()\n",
    "    test_predictions = clf.predict(test_embeddings.cpu().numpy())\n",
    "    inference_time = (time.time() - start_time) / len(test_texts)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(test_labels.cpu().numpy(), test_predictions)\n",
    "    f1 = f1_score(test_labels.cpu().numpy(), test_predictions, average='weighted')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Inference Time: {inference_time * 1000:.2f} ms per sample\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return accuracy, f1, inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1700750-f3d2-4e6b-8d3b-e3a3902fd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'distilbert-base-nli-mean-tokens',\n",
    "    'bert-base-nli-mean-tokens',\n",
    "    'roberta-base-nli-mean-tokens',\n",
    "    'xlnet-base-nli-mean-tokens',\n",
    "    'electra-base-nli-mean-tokens'\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for model_name in models:\n",
    "    accuracy, f1, inference_time = evaluate_model(model_name, train_texts, train_labels, test_texts, test_labels)\n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'inference_time': inference_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ba879-2c40-4005-8536-2ac20ecc224c",
   "metadata": {},
   "source": [
    "Resource utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44488de8-7d7f-45ed-9998-b3411bf90a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def measure_resource_utilization(model_name):\n",
    "    # Load the model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Measure GPU memory usage before and after encoding\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        _ = model.encode(train_texts[:10], convert_to_tensor=True)\n",
    "        peak_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)  # Convert to MB\n",
    "    else:\n",
    "        peak_memory = 0  # No GPU available\n",
    "\n",
    "    return peak_memory\n",
    "\n",
    "for model_name in models:\n",
    "    peak_memory = measure_resource_utilization(model_name)\n",
    "    print(f\"Model: {model_name}, Peak Memory Usage: {peak_memory:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
